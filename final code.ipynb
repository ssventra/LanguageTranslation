{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"final code.ipynb","provenance":[],"collapsed_sections":[]},"kernel_info":{"name":"python3-azureml"},"kernelspec":{"display_name":"Python 3.6 - AzureML","language":"python","name":"python3-azureml"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"nteract":{"version":"nteract-front-end@1.0.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"63Ndk2BgZB9H"},"source":["# SSLT-E2K: Sequence to Sequence Language Translation from English to Konkani using Natural Language Processing"]},{"cell_type":"markdown","metadata":{"id":"bjZ3xTXlZoQp"},"source":["#### Importing Libraries"]},{"cell_type":"code","metadata":{"gather":{"logged":1615184089049},"gradient":{},"id":"cruvMP-16lxr"},"source":["import pandas as pd\n","import numpy as np\n","import string\n","from string import digits\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import re\n","import keras\n","import pickle\n","import tensorflow\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","from keras.models import load_model\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IduK3C-MZ6jC"},"source":["#### Importing Dataset"]},{"cell_type":"code","metadata":{"gather":{"logged":1615184097614},"gradient":{},"id":"_QdfsZ4660kn","colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"status":"error","timestamp":1620144892957,"user_tz":-330,"elapsed":4009,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"}},"outputId":"39c23b10-306c-4a9d-a393-cd784df94572"},"source":["lines= pd.read_csv('final_dataset.csv', names=['eng', 'konk'], header=None)\n","\n","lines.head(10)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-19907804e136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'konk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_dataset.csv'"]}]},{"cell_type":"code","metadata":{"gather":{"logged":1615184101070},"gradient":{},"id":"wHbsY-7h6lxt"},"source":["lines.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fvSfBEHCZ_iC"},"source":["#### Dataset Per-processing"]},{"cell_type":"code","metadata":{"gather":{"logged":1615184102588},"gradient":{},"id":"9bjqlJnw6lxu"},"source":["# Lowercase all characters\n","lines.eng = [x.lower() for x in lines.eng]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184103571},"id":"-k5HEHaQ6lxw"},"source":["# Remove all numbers from text\n","lines.eng = [re.sub(\"[1234567890]\",\"\",x) for x in lines.eng]\n","lines.eng = [re.sub(\"[\\u200d]\",\"\",x) for x in lines.eng]\n","lines.konk = [re.sub(\"[1234567890२३०८१५७९४६]\",\"\",x) for x in lines.konk]\n","lines.konk = [re.sub(\"[\\u200d]\",\"\",x) for x in lines.konk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184105383},"gradient":{"source_hidden":false},"jupyter":{"outputs_hidden":false},"id":"ceh2ndP4rkwR"},"source":["# Remove special character\n","lines.eng = [re.sub(\"`\",'',x) for x in lines.eng]\n","lines.konk = [re.sub(\"`\",'',x) for x in lines.konk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184106379},"gradient":{},"id":"xtmlDLsM6lxv"},"source":["# Remove quotes\n","lines.eng = [re.sub(\"'\",'',x) for x in lines.eng]\n","lines.konk = [re.sub(\"'\",'',x) for x in lines.konk]\n","lines.eng = [re.sub(\"‘\",'',x) for x in lines.eng]\n","lines.konk = [re.sub(\"‘\",'',x) for x in lines.konk]\n","lines.eng = [re.sub(\"’\",'',x) for x in lines.eng]\n","lines.konk = [re.sub(\"’\",'',x) for x in lines.konk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184113100},"id":"dpyRcQEO6lxw"},"source":["# Remove extra spaces\n","lines.eng = [x.strip() for x in lines.eng]\n","lines.konk = [x.strip() for x in lines.konk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184114918},"id":"n7fCRn026lxv"},"source":["exclude = set(string.punctuation) # Set of all special characters\n","\n","# Remove all the special characters\n","lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n","lines.konk=lines.konk.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184115596},"id":"MX6KEDwO6lxx"},"source":["# Add start and end tokens to target sequences\n","lines.konk = ['START_ '+ x + ' _END' for x in lines.konk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"gather":{"logged":1615184117095},"id":"TCTTCx2R6lxx","executionInfo":{"elapsed":7766,"status":"ok","timestamp":1613326769768,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"b183bc1e-9ef1-453e-fb43-8812b7f0b35d"},"source":["lines.sample(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>konk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16283</th>\n","      <td>there is a taxi facility to go to neelkanth</td>\n","      <td>START_ निलकंठाक वचपा खातीर टॅक्सींची वेवस्था आ...</td>\n","    </tr>\n","    <tr>\n","      <th>54517</th>\n","      <td>the mahamastakabhisheka held in  and the compl...</td>\n","      <td>START_ वर्सा आयोजीत महामस्तकाभिशेक आनी मुर्तीच...</td>\n","    </tr>\n","    <tr>\n","      <th>15310</th>\n","      <td>some fatty substances or oils may also be given</td>\n","      <td>START_ कांय चरबी आशिल्ले पदार्थ वा तेल लेगीत द...</td>\n","    </tr>\n","    <tr>\n","      <th>4260</th>\n","      <td>take time to meditate in solitude</td>\n","      <td>START_ एकांतांत ध्यान  मेडिटेशन  करपा खातीर वे...</td>\n","    </tr>\n","    <tr>\n","      <th>45401</th>\n","      <td>popularly known as domuhani this place is a pi...</td>\n","      <td>START_ दोमुहानी नांवान लोकप्रीय ही सुवात खडकई ...</td>\n","    </tr>\n","    <tr>\n","      <th>50438</th>\n","      <td>deshsewa and was dedicated then press and jour...</td>\n","      <td>START_ देशसेवा आनी जनरुचीचे शुध्दीकरणाचे म्हान...</td>\n","    </tr>\n","    <tr>\n","      <th>10092</th>\n","      <td>large pandals are made from place to place</td>\n","      <td>START_ जाग्या जाग्यार व्हड व्हड माटव घालतात _END</td>\n","    </tr>\n","    <tr>\n","      <th>27992</th>\n","      <td>gujarati hindi english urdu and portuguese are...</td>\n","      <td>START_ गुजराती  हिंदी  इंग्लेज  उर्दू आनी पुर्...</td>\n","    </tr>\n","    <tr>\n","      <th>57068</th>\n","      <td>they do not face any kind of trouble even on l...</td>\n","      <td>START_ उणी न्हीद घेवन लेगीत तांकां कसलेच तरेचे...</td>\n","    </tr>\n","    <tr>\n","      <th>46469</th>\n","      <td>this says salman  i definitely want to but wil...</td>\n","      <td>START_ हाचेर सलमान म्हणटा  निश्चीतच जाय पूण खं...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     eng  \\\n","16283        there is a taxi facility to go to neelkanth   \n","54517  the mahamastakabhisheka held in  and the compl...   \n","15310    some fatty substances or oils may also be given   \n","4260                   take time to meditate in solitude   \n","45401  popularly known as domuhani this place is a pi...   \n","50438  deshsewa and was dedicated then press and jour...   \n","10092         large pandals are made from place to place   \n","27992  gujarati hindi english urdu and portuguese are...   \n","57068  they do not face any kind of trouble even on l...   \n","46469  this says salman  i definitely want to but wil...   \n","\n","                                                    konk  \n","16283  START_ निलकंठाक वचपा खातीर टॅक्सींची वेवस्था आ...  \n","54517  START_ वर्सा आयोजीत महामस्तकाभिशेक आनी मुर्तीच...  \n","15310  START_ कांय चरबी आशिल्ले पदार्थ वा तेल लेगीत द...  \n","4260   START_ एकांतांत ध्यान  मेडिटेशन  करपा खातीर वे...  \n","45401  START_ दोमुहानी नांवान लोकप्रीय ही सुवात खडकई ...  \n","50438  START_ देशसेवा आनी जनरुचीचे शुध्दीकरणाचे म्हान...  \n","10092   START_ जाग्या जाग्यार व्हड व्हड माटव घालतात _END  \n","27992  START_ गुजराती  हिंदी  इंग्लेज  उर्दू आनी पुर्...  \n","57068  START_ उणी न्हीद घेवन लेगीत तांकां कसलेच तरेचे...  \n","46469  START_ हाचेर सलमान म्हणटा  निश्चीतच जाय पूण खं...  "]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"OR_vA9W9aJYp"},"source":["#### Creating English-Konknai Vocabulary"]},{"cell_type":"code","metadata":{"gather":{"logged":1615184120364},"id":"kRxL2c-N6lxx"},"source":["# Vocabulary of English\n","all_eng_words=set()\n","for eng in lines.eng:\n","    for word in eng.split():\n","        if word not in all_eng_words:\n","            all_eng_words.add(word)\n","\n","# Vocabulary of Konkani \n","all_konkani_words=set()\n","for konk in lines.konk:\n","    for word in konk.split():\n","        if word not in all_konkani_words:\n","            all_konkani_words.add(word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1615184121697},"id":"IYXoEgtC6lxy","executionInfo":{"elapsed":7751,"status":"ok","timestamp":1613326769772,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"29a7f4a2-02dd-4950-b40b-0eb402eaeb8e"},"source":["# Max Length of source sequence\n","length_list=[]\n","for l in lines.eng:\n","    length_list.append(len(l.split(' ')))\n","max_length_src = np.max(length_list)\n","max_length_src"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1615184123731},"id":"CiwCRqRE6lxy","executionInfo":{"elapsed":7742,"status":"ok","timestamp":1613326769774,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"2b34bc27-e6c6-4ec2-a445-c65a0723b902"},"source":["# Max Length of target sequence\n","length_list=[]\n","for l in lines.konk:\n","    length_list.append(len(l.split(' ')))\n","max_length_tar = np.max(length_list)\n","max_length_tar"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["52"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1615184125549},"id":"1J2jmp3z6lxz","executionInfo":{"elapsed":7736,"status":"ok","timestamp":1613326769778,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"9fc1a615-f441-44ea-9bf0-3b5c17fdd941"},"source":["input_words = sorted(list(all_eng_words))\n","target_words = sorted(list(all_konkani_words))\n","num_encoder_tokens = len(all_eng_words)\n","num_decoder_tokens = len(all_konkani_words)\n","num_encoder_tokens, num_decoder_tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(38157, 89434)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1615184128087},"id":"d7pLLWDB6lxz","executionInfo":{"elapsed":7726,"status":"ok","timestamp":1613326769781,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"c393fbc0-d45a-4e34-a9aa-ca647e316e25"},"source":["num_decoder_tokens += 1 # For zero padding\n","num_decoder_tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["89435"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"gather":{"logged":1615184130268},"id":"svcTcse16lxz"},"source":["input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n","target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184131244},"id":"UQvpaXFj6lxz"},"source":["reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n","reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"gather":{"logged":1615184133132},"id":"l9oKE5Zr6lx0","executionInfo":{"elapsed":7705,"status":"ok","timestamp":1613326769791,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"95c7e2eb-38f9-4a71-b497-db0463b7b9bf"},"source":["lines = shuffle(lines)\n","lines.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>konk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>35887</th>\n","      <td>anemia medication is given to reduce bleeding ...</td>\n","      <td>START_ रक्तस्राव उणो करपाचें वा दूख उणावपाचें ...</td>\n","    </tr>\n","    <tr>\n","      <th>56690</th>\n","      <td>the birds found in the great himalayan nationa...</td>\n","      <td>START_ ग्रेट हिमालयन राष्ट्रीय उद्यानांत मेळपी...</td>\n","    </tr>\n","    <tr>\n","      <th>32732</th>\n","      <td>in blind piles there are no warts on the outsi...</td>\n","      <td>START_ वाये पसून जाल्ल्या बिकांत भोंकाचे भायले...</td>\n","    </tr>\n","    <tr>\n","      <th>31519</th>\n","      <td>also both actors is hosted jointly by the fift...</td>\n","      <td>START_ हाचे खेरीज दोनांय अभिनेत्यांनी  बिग बॉस...</td>\n","    </tr>\n","    <tr>\n","      <th>15449</th>\n","      <td>tagore knew no english no one knows indian eng...</td>\n","      <td>START_ टागोराक इंग्लीश कळना खंयच्याच भारतियाक ...</td>\n","    </tr>\n","    <tr>\n","      <th>45722</th>\n","      <td>take the melon pulp and rub it gently on the a...</td>\n","      <td>START_ काळंगाचो गर घेयात आनी ताका  ब्लॅक हेड्स...</td>\n","    </tr>\n","    <tr>\n","      <th>60813</th>\n","      <td>village by the ministry of agriculture the vil...</td>\n","      <td>START_ कृषी मंत्रालयाच्या वतीन गांवागांवानी गु...</td>\n","    </tr>\n","    <tr>\n","      <th>18933</th>\n","      <td>it is not possible to cultivate it in unirriga...</td>\n","      <td>START_ शिंपूंक नाशिल्ल्या क्षेत्रांनी हाची शेत...</td>\n","    </tr>\n","    <tr>\n","      <th>23256</th>\n","      <td>good luck at a reasonable price is typical of ...</td>\n","      <td>START_ योग्य दरेन बरो थातोमातो हें गणगौर पॅलेस...</td>\n","    </tr>\n","    <tr>\n","      <th>12950</th>\n","      <td>behu singh ji were a contemporary buffoon mast...</td>\n","      <td>START_ बेहू सिंहाचो एक समकालीन सवंग गुरू मूलरा...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     eng  \\\n","35887  anemia medication is given to reduce bleeding ...   \n","56690  the birds found in the great himalayan nationa...   \n","32732  in blind piles there are no warts on the outsi...   \n","31519  also both actors is hosted jointly by the fift...   \n","15449  tagore knew no english no one knows indian eng...   \n","45722  take the melon pulp and rub it gently on the a...   \n","60813  village by the ministry of agriculture the vil...   \n","18933  it is not possible to cultivate it in unirriga...   \n","23256  good luck at a reasonable price is typical of ...   \n","12950  behu singh ji were a contemporary buffoon mast...   \n","\n","                                                    konk  \n","35887  START_ रक्तस्राव उणो करपाचें वा दूख उणावपाचें ...  \n","56690  START_ ग्रेट हिमालयन राष्ट्रीय उद्यानांत मेळपी...  \n","32732  START_ वाये पसून जाल्ल्या बिकांत भोंकाचे भायले...  \n","31519  START_ हाचे खेरीज दोनांय अभिनेत्यांनी  बिग बॉस...  \n","15449  START_ टागोराक इंग्लीश कळना खंयच्याच भारतियाक ...  \n","45722  START_ काळंगाचो गर घेयात आनी ताका  ब्लॅक हेड्स...  \n","60813  START_ कृषी मंत्रालयाच्या वतीन गांवागांवानी गु...  \n","18933  START_ शिंपूंक नाशिल्ल्या क्षेत्रांनी हाची शेत...  \n","23256  START_ योग्य दरेन बरो थातोमातो हें गणगौर पॅलेस...  \n","12950  START_ बेहू सिंहाचो एक समकालीन सवंग गुरू मूलरा...  "]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"GGZsC1XoaSPL"},"source":["#### Defining Train-Test Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1615184135987},"id":"1eqmds246lx0","executionInfo":{"elapsed":7695,"status":"ok","timestamp":1613326769793,"user":{"displayName":"Final Year Project","photoUrl":"","userId":"08549056155906120522"},"user_tz":-330},"outputId":"4665b500-d436-4cd2-f0c2-ba614fce79f4"},"source":["# Train - Test Split (80-20)\n","X, y = lines.eng, lines.konk\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","X_train.shape, X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((52428,), (13108,))"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"IKaKQSYL6lx0"},"source":["#### Save the train and test dataframes for reproducing the results later, as they are shuffled."]},{"cell_type":"code","metadata":{"gather":{"logged":1615184138336},"id":"46Th-0uP6lx1"},"source":["X_train.to_pickle('X_train.pkl')\n","X_test.to_pickle('X_test.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184139554},"id":"q2Dlw63t6lx1"},"source":["def generate_batch(X = X_train, y = y_train, batch_size = 256):\n","    ''' Generate a batch of data '''\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n","            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n","            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n","            print(encoder_input_data)\n","            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n","                for t, word in enumerate(input_text.split()):\n","                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n","                for t, word in enumerate(target_text.split()):\n","                    if t<len(target_text.split())-1:\n","                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n","                    if t>0:\n","                        # decoder target sequence (one hot encoded)\n","                        # does not include the START_ token\n","                        # Offset by one timestep\n","                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n","            yield([encoder_input_data, decoder_input_data], decoder_target_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"stNsO8Tv6lx1"},"source":["#### Encoder - Decoder Model Architecture"]},{"cell_type":"code","metadata":{"gather":{"logged":1615184141777},"id":"r53oncgz6lx2"},"source":["latent_dim = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615184144983},"id":"KbN9qyjq6lx2"},"source":["# Encoder\n","encoder_inputs = Input(shape=(None,))\n","enc_emb =  Embedding(num_encoder_tokens +1, latent_dim, mask_zero = True)(encoder_inputs)\n","encoder_lstm = LSTM(latent_dim, dropout = 0.5, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615190391554},"id":"8kuRQWLX6lx2"},"source":["# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None,))\n","dec_emb_layer = Embedding(num_decoder_tokens +1, latent_dim, mask_zero = True)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","\n","# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, dropout = 0.5, return_sequences=True, return_state=True)\n","\n","decoder_outputs, _, _ = decoder_lstm(dec_emb,\n","                                     initial_state=encoder_states)\n","\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615190401607},"id":"gOBLCI9Frkwo"},"source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","batch_size = 256\n","epochs = 110"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615190516850},"id":"gR12qxv66lx3"},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1615190520872},"id":"sMNHnhGZrkwr","outputId":"9dac6979-e4f4-408f-ad99-509c7f1d74f4"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, None, 100)    3815800     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 100)    8943600     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 100),  80400       embedding_1[0][0]                \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 89435)  9032935     lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 21,953,135\n","Trainable params: 21,953,135\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7JN_P2xWam3z"},"source":["#### Training the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D97TQ4jb6lx4","outputId":"163807f8-8fb2-40d3-f4d8-f935f8814a90"},"source":["history=model.fit\\(generate_batch(X_train, y_train, batch_size = batch_size),\n","                    steps_per_epoch = train_samples//batch_size,\n","                    epochs=epochs,\n","                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n","                    validation_steps = val_samples//batch_size)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/125\n","204/204 [==============================] - 1485s 7s/step - loss: 2.3239 - acc: 0.0758 - val_loss: 1.9739 - val_acc: 0.0934\n","Epoch 2/125\n","204/204 [==============================] - 1461s 7s/step - loss: 1.9273 - acc: 0.0969 - val_loss: 1.9362 - val_acc: 0.1027\n","Epoch 3/125\n","204/204 [==============================] - 1492s 7s/step - loss: 1.8799 - acc: 0.1033 - val_loss: 1.9228 - val_acc: 0.1058\n","Epoch 4/125\n","204/204 [==============================] - 1460s 7s/step - loss: 1.8485 - acc: 0.1073 - val_loss: 1.9158 - val_acc: 0.1077\n","Epoch 5/125\n","204/204 [==============================] - 1495s 7s/step - loss: 1.8239 - acc: 0.1113 - val_loss: 1.9009 - val_acc: 0.1123\n","Epoch 6/125\n","204/204 [==============================] - 1459s 7s/step - loss: 1.7933 - acc: 0.1171 - val_loss: 1.8798 - val_acc: 0.1168\n","Epoch 7/125\n","204/204 [==============================] - 1463s 7s/step - loss: 1.7574 - acc: 0.1249 - val_loss: 1.8550 - val_acc: 0.1265\n","Epoch 8/125\n","204/204 [==============================] - 1494s 7s/step - loss: 1.7201 - acc: 0.1336 - val_loss: 1.8361 - val_acc: 0.1312\n","Epoch 9/125\n","204/204 [==============================] - 1453s 7s/step - loss: 1.6833 - acc: 0.1397 - val_loss: 1.8165 - val_acc: 0.1349\n","Epoch 10/125\n","204/204 [==============================] - 1494s 7s/step - loss: 1.6471 - acc: 0.1455 - val_loss: 1.7981 - val_acc: 0.1395\n","Epoch 11/125\n","204/204 [==============================] - 1455s 7s/step - loss: 1.6136 - acc: 0.1522 - val_loss: 1.7854 - val_acc: 0.1445\n","Epoch 12/125\n","204/204 [==============================] - 1466s 7s/step - loss: 1.5797 - acc: 0.1588 - val_loss: 1.7747 - val_acc: 0.1484\n","Epoch 13/125\n","204/204 [==============================] - 1488s 7s/step - loss: 1.5507 - acc: 0.1646 - val_loss: 1.7610 - val_acc: 0.1511\n","Epoch 14/125\n","204/204 [==============================] - 1448s 7s/step - loss: 1.5191 - acc: 0.1713 - val_loss: 1.7501 - val_acc: 0.1555\n","Epoch 15/125\n","204/204 [==============================] - 1489s 7s/step - loss: 1.4910 - acc: 0.1770 - val_loss: 1.7429 - val_acc: 0.1582\n","Epoch 16/125\n","204/204 [==============================] - 1447s 7s/step - loss: 1.4610 - acc: 0.1825 - val_loss: 1.7365 - val_acc: 0.1614\n","Epoch 17/125\n","204/204 [==============================] - 1452s 7s/step - loss: 1.4338 - acc: 0.1883 - val_loss: 1.7318 - val_acc: 0.1635\n","Epoch 18/125\n","204/204 [==============================] - 1473s 7s/step - loss: 1.4082 - acc: 0.1935 - val_loss: 1.7223 - val_acc: 0.1666\n","Epoch 19/125\n","204/204 [==============================] - 1453s 7s/step - loss: 1.3838 - acc: 0.1989 - val_loss: 1.7179 - val_acc: 0.1678\n","Epoch 20/125\n","204/204 [==============================] - 1484s 7s/step - loss: 1.3573 - acc: 0.2035 - val_loss: 1.7164 - val_acc: 0.1694\n","Epoch 21/125\n","204/204 [==============================] - 1446s 7s/step - loss: 1.3317 - acc: 0.2085 - val_loss: 1.7153 - val_acc: 0.1712\n","Epoch 22/125\n","204/204 [==============================] - 1466s 7s/step - loss: 1.3071 - acc: 0.2135 - val_loss: 1.7121 - val_acc: 0.1732\n","Epoch 23/125\n","204/204 [==============================] - 1469s 7s/step - loss: 1.2854 - acc: 0.2175 - val_loss: 1.7107 - val_acc: 0.1749\n","Epoch 24/125\n","204/204 [==============================] - 1462s 7s/step - loss: 1.2650 - acc: 0.2216 - val_loss: 1.7068 - val_acc: 0.1760\n","Epoch 25/125\n","204/204 [==============================] - 1486s 7s/step - loss: 1.2414 - acc: 0.2259 - val_loss: 1.7036 - val_acc: 0.1760\n","Epoch 26/125\n","204/204 [==============================] - 1444s 7s/step - loss: 1.2191 - acc: 0.2310 - val_loss: 1.7046 - val_acc: 0.1751\n","Epoch 27/125\n","204/204 [==============================] - 1465s 7s/step - loss: 1.1977 - acc: 0.2360 - val_loss: 1.7045 - val_acc: 0.1766\n","Epoch 28/125\n","204/204 [==============================] - 1454s 7s/step - loss: 1.1784 - acc: 0.2400 - val_loss: 1.7036 - val_acc: 0.1800\n","Epoch 29/125\n","204/204 [==============================] - 1452s 7s/step - loss: 1.1591 - acc: 0.2451 - val_loss: 1.7090 - val_acc: 0.1808\n","Epoch 30/125\n","204/204 [==============================] - 1488s 7s/step - loss: 1.1395 - acc: 0.2488 - val_loss: 1.7146 - val_acc: 0.1818\n","Epoch 31/125\n","204/204 [==============================] - 1463s 7s/step - loss: 1.1213 - acc: 0.2546 - val_loss: 1.7158 - val_acc: 0.1824\n","Epoch 32/125\n","204/204 [==============================] - 1481s 7s/step - loss: 1.1003 - acc: 0.2608 - val_loss: 1.7138 - val_acc: 0.1825\n","Epoch 33/125\n","204/204 [==============================] - 1447s 7s/step - loss: 1.0807 - acc: 0.2673 - val_loss: 1.7134 - val_acc: 0.1831\n","Epoch 34/125\n","204/204 [==============================] - 1444s 7s/step - loss: 1.0632 - acc: 0.2751 - val_loss: 1.7149 - val_acc: 0.1836\n","Epoch 35/125\n","204/204 [==============================] - 1487s 7s/step - loss: 1.0443 - acc: 0.2831 - val_loss: 1.7179 - val_acc: 0.1831\n","Epoch 36/125\n","204/204 [==============================] - 1444s 7s/step - loss: 1.0263 - acc: 0.2907 - val_loss: 1.7199 - val_acc: 0.1831\n","Epoch 37/125\n","204/204 [==============================] - 1482s 7s/step - loss: 1.0105 - acc: 0.2995 - val_loss: 1.7232 - val_acc: 0.1840\n","Epoch 38/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.9928 - acc: 0.3089 - val_loss: 1.7280 - val_acc: 0.1851\n","Epoch 39/125\n","204/204 [==============================] - 1459s 7s/step - loss: 0.9776 - acc: 0.3173 - val_loss: 1.7333 - val_acc: 0.1851\n","Epoch 40/125\n","204/204 [==============================] - 1496s 7s/step - loss: 0.9606 - acc: 0.3258 - val_loss: 1.7385 - val_acc: 0.1854\n","Epoch 41/125\n","204/204 [==============================] - 1482s 7s/step - loss: 0.9449 - acc: 0.3341 - val_loss: 1.7415 - val_acc: 0.1854\n","Epoch 42/125\n","204/204 [==============================] - 1489s 7s/step - loss: 0.9293 - acc: 0.3428 - val_loss: 1.7439 - val_acc: 0.1855\n","Epoch 43/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.9153 - acc: 0.3513 - val_loss: 1.7503 - val_acc: 0.1849\n","Epoch 44/125\n","204/204 [==============================] - 1459s 7s/step - loss: 0.9021 - acc: 0.3588 - val_loss: 1.7543 - val_acc: 0.1848\n","Epoch 45/125\n","204/204 [==============================] - 1476s 7s/step - loss: 0.8894 - acc: 0.3662 - val_loss: 1.7582 - val_acc: 0.1859\n","Epoch 46/125\n","204/204 [==============================] - 1450s 7s/step - loss: 0.8772 - acc: 0.3728 - val_loss: 1.7607 - val_acc: 0.1855\n","Epoch 47/125\n","204/204 [==============================] - 1490s 7s/step - loss: 0.8644 - acc: 0.3814 - val_loss: 1.7630 - val_acc: 0.1848\n","Epoch 48/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.8502 - acc: 0.3887 - val_loss: 1.7677 - val_acc: 0.1833\n","Epoch 49/125\n","204/204 [==============================] - 1461s 7s/step - loss: 0.8385 - acc: 0.3956 - val_loss: 1.7724 - val_acc: 0.1836\n","Epoch 50/125\n","204/204 [==============================] - 1464s 7s/step - loss: 0.8274 - acc: 0.4028 - val_loss: 1.7775 - val_acc: 0.1850\n","Epoch 51/125\n","204/204 [==============================] - 1455s 7s/step - loss: 0.8158 - acc: 0.4087 - val_loss: 1.7844 - val_acc: 0.1859\n","Epoch 52/125\n","204/204 [==============================] - 1491s 7s/step - loss: 0.8043 - acc: 0.4146 - val_loss: 1.7895 - val_acc: 0.1859\n","Epoch 53/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.7938 - acc: 0.4211 - val_loss: 1.7931 - val_acc: 0.1860\n","Epoch 54/125\n","204/204 [==============================] - 1473s 7s/step - loss: 0.7827 - acc: 0.4263 - val_loss: 1.7970 - val_acc: 0.1850\n","Epoch 55/125\n","204/204 [==============================] - 1454s 7s/step - loss: 0.7736 - acc: 0.4330 - val_loss: 1.8010 - val_acc: 0.1846\n","Epoch 56/125\n","204/204 [==============================] - 1451s 7s/step - loss: 0.7634 - acc: 0.4383 - val_loss: 1.8063 - val_acc: 0.1845\n","Epoch 57/125\n","204/204 [==============================] - 1489s 7s/step - loss: 0.7551 - acc: 0.4434 - val_loss: 1.8112 - val_acc: 0.1841\n","Epoch 58/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.7459 - acc: 0.4491 - val_loss: 1.8162 - val_acc: 0.1841\n","Epoch 59/125\n","204/204 [==============================] - 1485s 7s/step - loss: 0.7378 - acc: 0.4528 - val_loss: 1.8205 - val_acc: 0.1843\n","Epoch 60/125\n","204/204 [==============================] - 1452s 7s/step - loss: 0.7285 - acc: 0.4583 - val_loss: 1.8252 - val_acc: 0.1837\n","Epoch 61/125\n","204/204 [==============================] - 1450s 7s/step - loss: 0.7195 - acc: 0.4636 - val_loss: 1.8298 - val_acc: 0.1836\n","Epoch 62/125\n","204/204 [==============================] - 1486s 7s/step - loss: 0.7121 - acc: 0.4684 - val_loss: 1.8343 - val_acc: 0.1837\n","Epoch 63/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.7055 - acc: 0.4719 - val_loss: 1.8394 - val_acc: 0.1839\n","Epoch 64/125\n","204/204 [==============================] - 1477s 7s/step - loss: 0.6982 - acc: 0.4764 - val_loss: 1.8442 - val_acc: 0.1838\n","Epoch 65/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.6919 - acc: 0.4799 - val_loss: 1.8497 - val_acc: 0.1839\n","Epoch 66/125\n","204/204 [==============================] - 1482s 7s/step - loss: 0.6787 - acc: 0.4878 - val_loss: 1.8598 - val_acc: 0.1820\n","Epoch 68/125\n","204/204 [==============================] - 1451s 7s/step - loss: 0.6725 - acc: 0.4916 - val_loss: 1.8644 - val_acc: 0.1817\n","Epoch 69/125\n","204/204 [==============================] - 1497s 7s/step - loss: 0.6661 - acc: 0.4951 - val_loss: 1.8672 - val_acc: 0.1809\n","Epoch 70/125\n","204/204 [==============================] - 1450s 7s/step - loss: 0.6603 - acc: 0.4991 - val_loss: 1.8702 - val_acc: 0.1803\n","Epoch 71/125\n","204/204 [==============================] - 1450s 7s/step - loss: 0.6537 - acc: 0.5026 - val_loss: 1.8747 - val_acc: 0.1797\n","204/204 [==============================] - 1446s 7s/step - loss: 0.6436 - acc: 0.5091 - val_loss: 1.8824 - val_acc: 0.1796\n","Epoch 74/125\n","204/204 [==============================] - 1487s 7s/step - loss: 0.6378 - acc: 0.5117 - val_loss: 1.8857 - val_acc: 0.1821\n","Epoch 75/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.6312 - acc: 0.5159 - val_loss: 1.8940 - val_acc: 0.1840\n","Epoch 76/125\n","204/204 [==============================] - 1452s 7s/step - loss: 0.6253 - acc: 0.5185 - val_loss: 1.9009 - val_acc: 0.1844\n","Epoch 77/125\n","204/204 [==============================] - 1473s 7s/step - loss: 0.6198 - acc: 0.5226 - val_loss: 1.9062 - val_acc: 0.1845\n","Epoch 78/125\n","204/204 [==============================] - 1460s 7s/step - loss: 0.6141 - acc: 0.5253 - val_loss: 1.9085 - val_acc: 0.1837\n","Epoch 79/125\n","204/204 [==============================] - 1496s 7s/step - loss: 0.6073 - acc: 0.5291 - val_loss: 1.9117 - val_acc: 0.1825\n","Epoch 80/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.6011 - acc: 0.5327 - val_loss: 1.9149 - val_acc: 0.1815\n","Epoch 81/125\n","204/204 [==============================] - 1459s 7s/step - loss: 0.5967 - acc: 0.5363 - val_loss: 1.9204 - val_acc: 0.1810\n","Epoch 82/125\n","204/204 [==============================] - 1465s 7s/step - loss: 0.5907 - acc: 0.5399 - val_loss: 1.9262 - val_acc: 0.1810\n","Epoch 83/125\n","204/204 [==============================] - 1453s 7s/step - loss: 0.5858 - acc: 0.5424 - val_loss: 1.9315 - val_acc: 0.1809\n","Epoch 84/125\n","204/204 [==============================] - 1483s 7s/step - loss: 0.5801 - acc: 0.5466 - val_loss: 1.9382 - val_acc: 0.1806\n","Epoch 85/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.5752 - acc: 0.5493 - val_loss: 1.9453 - val_acc: 0.1806\n","Epoch 86/125\n","204/204 [==============================] - 1475s 7s/step - loss: 0.5711 - acc: 0.5521 - val_loss: 1.9478 - val_acc: 0.1799\n","Epoch 87/125\n","204/204 [==============================] - 1445s 7s/step - loss: 0.5656 - acc: 0.5560 - val_loss: 1.9514 - val_acc: 0.1795\n","Epoch 88/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.5615 - acc: 0.5589 - val_loss: 1.9553 - val_acc: 0.1785\n","Epoch 89/125\n","204/204 [==============================] - 1482s 7s/step - loss: 0.5569 - acc: 0.5616 - val_loss: 1.9585 - val_acc: 0.1774\n","Epoch 90/125\n","204/204 [==============================] - 1452s 7s/step - loss: 0.5528 - acc: 0.5638 - val_loss: 1.9631 - val_acc: 0.1766\n","Epoch 91/125\n","204/204 [==============================] - 1477s 7s/step - loss: 0.5480 - acc: 0.5661 - val_loss: 1.9664 - val_acc: 0.1755\n","Epoch 92/125\n","204/204 [==============================] - 1450s 7s/step - loss: 0.5427 - acc: 0.5700 - val_loss: 1.9707 - val_acc: 0.1757\n","Epoch 93/125\n","204/204 [==============================] - 1455s 7s/step - loss: 0.5393 - acc: 0.5721 - val_loss: 1.9748 - val_acc: 0.1768\n","Epoch 94/125\n","204/204 [==============================] - 1490s 7s/step - loss: 0.5361 - acc: 0.5748 - val_loss: 1.9789 - val_acc: 0.1775\n","Epoch 95/125\n","204/204 [==============================] - 1442s 7s/step - loss: 0.5322 - acc: 0.5768 - val_loss: 1.9832 - val_acc: 0.1783\n","Epoch 96/125\n","204/204 [==============================] - 1476s 7s/step - loss: 0.5274 - acc: 0.5795 - val_loss: 1.9881 - val_acc: 0.1783\n","Epoch 97/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.5246 - acc: 0.5816 - val_loss: 1.9928 - val_acc: 0.1781\n","Epoch 98/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.5217 - acc: 0.5841 - val_loss: 1.9990 - val_acc: 0.1784\n","Epoch 99/125\n","204/204 [==============================] - 1482s 7s/step - loss: 0.5166 - acc: 0.5861 - val_loss: 2.0014 - val_acc: 0.1779\n","Epoch 100/125\n","204/204 [==============================] - 1445s 7s/step - loss: 0.5126 - acc: 0.5890 - val_loss: 2.0055 - val_acc: 0.1776\n","Epoch 101/125\n","204/204 [==============================] - 1483s 7s/step - loss: 0.5090 - acc: 0.5912 - val_loss: 2.0071 - val_acc: 0.1765\n","Epoch 102/125\n","204/204 [==============================] - 1445s 7s/step - loss: 0.5073 - acc: 0.5922 - val_loss: 2.0093 - val_acc: 0.1762\n","Epoch 103/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.5037 - acc: 0.5952 - val_loss: 2.0142 - val_acc: 0.1759\n","Epoch 104/125\n","204/204 [==============================] - 1482s 7s/step - loss: 0.5005 - acc: 0.5971 - val_loss: 2.0191 - val_acc: 0.1766\n","Epoch 105/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.4973 - acc: 0.5990 - val_loss: 2.0237 - val_acc: 0.1773\n","Epoch 106/125\n","204/204 [==============================] - 1491s 7s/step - loss: 0.4953 - acc: 0.6000 - val_loss: 2.0287 - val_acc: 0.1777\n","Epoch 107/125\n","204/204 [==============================] - 1452s 7s/step - loss: 0.4924 - acc: 0.6018 - val_loss: 2.0366 - val_acc: 0.1776\n","Epoch 108/125\n","204/204 [==============================] - 1463s 7s/step - loss: 0.4901 - acc: 0.6037 - val_loss: 2.0412 - val_acc: 0.1774\n","Epoch 109/125\n","204/204 [==============================] - 1477s 7s/step - loss: 0.4868 - acc: 0.6052 - val_loss: 2.0436 - val_acc: 0.1769\n","Epoch 110/125\n","204/204 [==============================] - 1455s 7s/step - loss: 0.4821 - acc: 0.6083 - val_loss: 2.0455 - val_acc: 0.1759\n","Epoch 111/125\n","204/204 [==============================] - 1486s 7s/step - loss: 0.4788 - acc: 0.6101 - val_loss: 2.0489 - val_acc: 0.1752\n","Epoch 112/125\n","204/204 [==============================] - 1448s 7s/step - loss: 0.4750 - acc: 0.6143 - val_loss: 2.0528 - val_acc: 0.1759\n","Epoch 113/125\n","204/204 [==============================] - 1465s 7s/step - loss: 0.4718 - acc: 0.6153 - val_loss: 2.0564 - val_acc: 0.1763\n","Epoch 114/125\n","204/204 [==============================] - 1459s 7s/step - loss: 0.4697 - acc: 0.6161 - val_loss: 2.0631 - val_acc: 0.1769\n","Epoch 115/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.4656 - acc: 0.6191 - val_loss: 2.0668 - val_acc: 0.1774\n","Epoch 116/125\n","204/204 [==============================] - 1486s 7s/step - loss: 0.4633 - acc: 0.6210 - val_loss: 2.0737 - val_acc: 0.1773\n","Epoch 117/125\n","204/204 [==============================] - 1446s 7s/step - loss: 0.4615 - acc: 0.6220 - val_loss: 2.0776 - val_acc: 0.1767\n","Epoch 118/125\n","204/204 [==============================] - 1473s 7s/step - loss: 0.4604 - acc: 0.6234 - val_loss: 2.0808 - val_acc: 0.1755\n","Epoch 119/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.4566 - acc: 0.6263 - val_loss: 2.0848 - val_acc: 0.1747\n","Epoch 120/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.4542 - acc: 0.6270 - val_loss: 2.0888 - val_acc: 0.1730\n","Epoch 121/125\n","204/204 [==============================] - 1487s 7s/step - loss: 0.4523 - acc: 0.6282 - val_loss: 2.0933 - val_acc: 0.1727\n","Epoch 122/125\n","204/204 [==============================] - 1447s 7s/step - loss: 0.4489 - acc: 0.6310 - val_loss: 2.0962 - val_acc: 0.1721\n","Epoch 123/125\n","204/204 [==============================] - 1478s 7s/step - loss: 0.4470 - acc: 0.6322 - val_loss: 2.1003 - val_acc: 0.1717\n","Epoch 124/125\n","204/204 [==============================] - 1449s 7s/step - loss: 0.4428 - acc: 0.6343 - val_loss: 2.1044 - val_acc: 0.1710\n","Epoch 125/125\n","204/204 [==============================] - 1446s 7s/step - loss: 0.4401 - acc: 0.6362 - val_loss: 2.1089 - val_acc: 0.1707\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z_aL96Ll6lx4"},"source":["#### Always remember to save the weights and model"]},{"cell_type":"code","metadata":{"id":"KJlUKOGy6lx5","outputId":"6e6beca5-470b-45b1-8e80-40f128ab7bae"},"source":["model.save_weights('weights_ss.h5')\n","print(\"Saved weights to disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved weights to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHS5cuUSrkwy","outputId":"ee39d5f1-7025-4df4-87ed-36ef14dc4b5d"},"source":["history = model.save('model_s.h5')\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aN3_H5A8rkwz"},"source":["Pkl_Filename = \"model_s.pkl\"  \n","\n","with open(Pkl_Filename, 'wb') as file:  \n","    pickle.dump(history, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFWKc33crkwz"},"source":["# Pickled_history = pickle.load(open('model_s.pkl','rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpOKHfKKrkw0","outputId":"1ca8862a-d6fa-41e0-ae47-016c9f33bd03"},"source":["# # save:\n","# f = open('model.pckl', 'wb')\n","# pickle.dump(history.history, f)\n","# f.close()\n","\n","# # retrieve:    \n","# f = open('model.pckl', 'rb')\n","# history = pickle.load(f)\n","# f.close()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'history'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-159-96c67a411754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# save:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pckl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"]}]},{"cell_type":"markdown","metadata":{"id":"wLkryC6q6lx5"},"source":["#### Load the weights, if you close the application"]},{"cell_type":"code","metadata":{"id":"uQpU-sFz6lx5"},"source":["model.load_weights('weights_ss.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LerBU3iNrkw-"},"source":["plt.plot(history.load['val_loss'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TBPqsObd6lx5"},"source":["#### Inference Setup"]},{"cell_type":"code","metadata":{"id":"bfuwee_h6lx5"},"source":["# Encode the input sequence to get the \"thought vectors\"\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# Decoder setup\n","# Below tensors will hold the states of the previous time step\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n","\n","# To predict the next word in the sequence, set the initial states to the states from the previous time step\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n","decoder_states2 = [state_h2, state_c2]\n","decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n","\n","# Final decoder model\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs2] + decoder_states2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQaPue_r6lx7"},"source":["#### Decode sample sequeces"]},{"cell_type":"code","metadata":{"id":"sdETmXzW6lx7"},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1,1))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0] = target_token_index['START_']\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += ' '+sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '_END' or\n","           len(decoded_sentence) > 50):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GQMkCpkm6lx7"},"source":["#### Evaluation on Train Dataset"]},{"cell_type":"code","metadata":{"id":"MH14cRFS6lx8"},"source":["train_gen = generate_batch(X_train, y_train, batch_size = 1)\n","k=-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faDKvD0N6lx8","outputId":"edacf304-1153-49d7-cf4b-7273906ca701"},"source":["#1\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: these states are less onion wholesale prices\n","Actual Konkani Translation:  ह्या राज्यांनीय कांद्याचे ठोक भाव कमी जाल्यांत \n","Predicted Konkani Translation:  ह्या राज्यांनीय कांद्याचे दर वर्सा विकसीत केलें \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6SPjjhBCdqHS"},"source":["#2\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCxypg1adsYw"},"source":["#3\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_MST2YseUOB"},"source":["#4\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vPEB-UKeWFb"},"source":["#5\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNAa2dCHeYw6"},"source":["#6\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8JpFwlReai_"},"source":["#7\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iftw6YfqecSu"},"source":["#8\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXFseMleed-t"},"source":["#9\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3W1itdFef9H"},"source":["#10\n","k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ot9uhvXm6lyH"},"source":["#### Evaluation on Validation Dataset"]},{"cell_type":"code","metadata":{"id":"yn0dFsYJ6lyH"},"source":["val_gen = generate_batch(X_test, y_test, batch_size = 1)\n","k=-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNbkdwve6lyI","outputId":"04b64004-ee99-47d9-dfd2-c85b1d1e5dec"},"source":["#1\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: workers working in cotton mills or plastic factories in industrial areas are susceptible to chronic bronchitisdisease\n","Actual Konkani Translation:  उद्येगीक वाठारांनी कापसाची गिरण वा प्लास्टिकाच्या कारखान्यांत काम करप्यांक कामगारांक  क्रॉनीक ब्रॉन्कायटीस  दुयेंस जावपाची शक्यताय आसता \n","Predicted Konkani Translation:  रेंवटाच्या वाठारा वांगडा इंडियन कुमार आनी केबल\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"buGzVwnF6lyI","outputId":"89e38207-20bc-4a8b-ca8c-2295cf783c62"},"source":["#2\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: so the country through the platform in swangon ends the question of introduction of the period\n","Actual Konkani Translation:  देखून ह्या सवंगानी मंचाच्या माध्यमांतल्यान देश काळाचो परीचय दिवपाचो प्रस्नच सोंपता \n","Predicted Konkani Translation:  देखून कृशी दसकांत ग्रामीण अर्थवेवस्थेंत पुराय \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jBYt_HBv6lyI","outputId":"c68b570c-3382-423d-9e5c-e4ebddccb521"},"source":["#3\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: camps can be set up here during the summer on the spring so that the natural climate and climate of the surroundings can be studied\n","Actual Konkani Translation:  वसंत मोसमाचे सुरवातीक कालोराच्या दिसांनी हांगा तंबू घालूं येता जाचे आशिकुशीचे सैमीक रानवटी वाठाराचो आनी हवामानाचो अभ्यास करूं येता \n","Predicted Konkani Translation:  नव्या वाठारांत तुमच्यांनी सैमीक देखावे मनाक आग\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lHcVzR5i6lyI","outputId":"0f4837b5-06d6-4fd8-a963-1b364cc13697"},"source":["#4\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: snow bridges tend to be unreliable due to the weakening of the day climbing\n","Actual Konkani Translation:  बर्फाचेर तयार जाल्ले पूल दीस वयर आयले उपरांत दुबळे पडिल्ल्या कारणान घातकी जावंक लागतात \n","Predicted Konkani Translation:  काठार एक्सपर्ट लोक जे दुयेंतीच्या कॅन्सराक पांयां\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fOnAHb8F6lyI","outputId":"73553320-6e2c-4d27-8d08-7caae2992897"},"source":["#5\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: during makar sankranti parashurama goes to take a dip in the sailani kund from far and wide\n","Actual Konkani Translation:  मकर सक्रांती वेळार परशुराम कुंडांत पयसुल्ल्यान भोंवडेकार कुंडांत न्हावपा खातीर येतात \n","Predicted Konkani Translation:  डिसेंबराचे डिसेंबराचे नाण्यांचो उपेग ट्रेल्स कुं\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XX6N4y4m6lyI","outputId":"61d4ce5e-21bb-4aaa-c2fe-86106cb0a1c6"},"source":["#6\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: this same information and comparison sometimes helps us in getting out of our grief\n","Actual Konkani Translation:  हीच म्हायती आनी तुळा जायत्या फावटीं आमी आमच्या दुख्खांतल्यान भायर सरपांत आमची मजत करता \n","Predicted Konkani Translation:  हे खातीर सुचना साम्राज्यवाद आतां जायत्या तरांच्यो तप\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p_YJ0gsA6lyJ","outputId":"6cae8f08-fe42-4915-e9e2-d3946bfef507"},"source":["#7\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: round the same texts references to a game of sports name\n","Actual Konkani Translation:  त्याच ग्रंथांत गोल क्रिडा नांवाचो एका खेळाचो उल्लेख जाला \n","Predicted Konkani Translation:  होंवरे उपरांत राधा गुरू शेख दाऊद रावताले \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0r-FZZFA6lyJ","outputId":"d9abc1c4-f72b-43e9-8ad9-8fe0d9b73214"},"source":["#8\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: listen to it too that harry had broken away from the heart of the model of the beautiful taylor they had left him\n","Actual Konkani Translation:  आयकुपाक तर हे लेगीत येता की हॅरीन सुंदर टेलराचे काळीज ज्या मॉडला खातीर तोडिल्लें ताणें तिका पसून सोडली \n","Predicted Konkani Translation:  ह्या देंवण्या लागीं सावन जेन्ना सावन अकरमा कडेन \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nJapqe376lyJ","outputId":"efb6241f-f713-4b79-896d-d5fda35582cc"},"source":["#9\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: large retail marketing areas india is the ninth place\n","Actual Konkani Translation:  व्हड किरकोळ वेपार धंदो आशिल्ल्या क्षेत्रांनी भारताक णव्वी सुवात प्राप्त जाल्या \n","Predicted Konkani Translation:  भारतांत भारतांत उसाची शेती भारतांतल्या एक विशाळ क\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sl0VLcE06lyM","outputId":"225d38d8-f972-48a9-e6d5-8621f4e765da"},"source":["#10\n","k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Konkani Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Konkani Translation:', decoded_sentence[:-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input English sentence: the havelis of jaisalmer which are its specialty are made of bright yellow stones\n","Actual Konkani Translation:  जैसलमेराचे वाडे जें हाचें खाशेलपण आसा  चकचकीत हळडुव्या फातरांनी बांदिल्ले आसात \n","Predicted Konkani Translation:  आधुनीक नदरेन जैन देवळाक दरगो आसा जें शत्रूं पसून वाट\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EpivSQ-AgF1m"},"source":["---"]}]}